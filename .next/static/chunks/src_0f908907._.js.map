{
  "version": 3,
  "sources": [],
  "sections": [
    {"offset": {"line": 7, "column": 0}, "map": {"version":3,"sources":["file:///home/user/studio/src/components/ui/card.tsx"],"sourcesContent":["import * as React from \"react\"\n\nimport { cn } from \"@/lib/utils\"\n\nconst Card = React.forwardRef<\n  HTMLDivElement,\n  React.HTMLAttributes<HTMLDivElement>\n>(({ className, ...props }, ref) => (\n  <div\n    ref={ref}\n    className={cn(\n      \"rounded-lg border bg-card text-card-foreground shadow-sm\",\n      className\n    )}\n    {...props}\n  />\n))\nCard.displayName = \"Card\"\n\nconst CardHeader = React.forwardRef<\n  HTMLDivElement,\n  React.HTMLAttributes<HTMLDivElement>\n>(({ className, ...props }, ref) => (\n  <div\n    ref={ref}\n    className={cn(\"flex flex-col space-y-1.5 p-6\", className)}\n    {...props}\n  />\n))\nCardHeader.displayName = \"CardHeader\"\n\nconst CardTitle = React.forwardRef<\n  HTMLDivElement,\n  React.HTMLAttributes<HTMLDivElement>\n>(({ className, ...props }, ref) => (\n  <div\n    ref={ref}\n    className={cn(\n      \"text-2xl font-semibold leading-none tracking-tight\",\n      className\n    )}\n    {...props}\n  />\n))\nCardTitle.displayName = \"CardTitle\"\n\nconst CardDescription = React.forwardRef<\n  HTMLDivElement,\n  React.HTMLAttributes<HTMLDivElement>\n>(({ className, ...props }, ref) => (\n  <div\n    ref={ref}\n    className={cn(\"text-sm text-muted-foreground\", className)}\n    {...props}\n  />\n))\nCardDescription.displayName = \"CardDescription\"\n\nconst CardContent = React.forwardRef<\n  HTMLDivElement,\n  React.HTMLAttributes<HTMLDivElement>\n>(({ className, ...props }, ref) => (\n  <div ref={ref} className={cn(\"p-6 pt-0\", className)} {...props} />\n))\nCardContent.displayName = \"CardContent\"\n\nconst CardFooter = React.forwardRef<\n  HTMLDivElement,\n  React.HTMLAttributes<HTMLDivElement>\n>(({ className, ...props }, ref) => (\n  <div\n    ref={ref}\n    className={cn(\"flex items-center p-6 pt-0\", className)}\n    {...props}\n  />\n))\nCardFooter.displayName = \"CardFooter\"\n\nexport { Card, CardHeader, CardFooter, CardTitle, CardDescription, CardContent }\n"],"names":[],"mappings":";;;;;;;;;AAAA;AAEA;;;;AAEA,MAAM,qBAAO,CAAA,GAAA,6JAAA,CAAA,aAAgB,AAAD,OAG1B,CAAC,EAAE,SAAS,EAAE,GAAG,OAAO,EAAE,oBAC1B,6LAAC;QACC,KAAK;QACL,WAAW,CAAA,GAAA,sHAAA,CAAA,KAAE,AAAD,EACV,4DACA;QAED,GAAG,KAAK;;;;;;;AAGb,KAAK,WAAW,GAAG;AAEnB,MAAM,2BAAa,CAAA,GAAA,6JAAA,CAAA,aAAgB,AAAD,QAGhC,CAAC,EAAE,SAAS,EAAE,GAAG,OAAO,EAAE,oBAC1B,6LAAC;QACC,KAAK;QACL,WAAW,CAAA,GAAA,sHAAA,CAAA,KAAE,AAAD,EAAE,iCAAiC;QAC9C,GAAG,KAAK;;;;;;;AAGb,WAAW,WAAW,GAAG;AAEzB,MAAM,0BAAY,CAAA,GAAA,6JAAA,CAAA,aAAgB,AAAD,QAG/B,CAAC,EAAE,SAAS,EAAE,GAAG,OAAO,EAAE,oBAC1B,6LAAC;QACC,KAAK;QACL,WAAW,CAAA,GAAA,sHAAA,CAAA,KAAE,AAAD,EACV,sDACA;QAED,GAAG,KAAK;;;;;;;AAGb,UAAU,WAAW,GAAG;AAExB,MAAM,gCAAkB,CAAA,GAAA,6JAAA,CAAA,aAAgB,AAAD,QAGrC,CAAC,EAAE,SAAS,EAAE,GAAG,OAAO,EAAE,oBAC1B,6LAAC;QACC,KAAK;QACL,WAAW,CAAA,GAAA,sHAAA,CAAA,KAAE,AAAD,EAAE,iCAAiC;QAC9C,GAAG,KAAK;;;;;;;AAGb,gBAAgB,WAAW,GAAG;AAE9B,MAAM,4BAAc,CAAA,GAAA,6JAAA,CAAA,aAAgB,AAAD,QAGjC,CAAC,EAAE,SAAS,EAAE,GAAG,OAAO,EAAE,oBAC1B,6LAAC;QAAI,KAAK;QAAK,WAAW,CAAA,GAAA,sHAAA,CAAA,KAAE,AAAD,EAAE,YAAY;QAAa,GAAG,KAAK;;;;;;;AAEhE,YAAY,WAAW,GAAG;AAE1B,MAAM,2BAAa,CAAA,GAAA,6JAAA,CAAA,aAAgB,AAAD,SAGhC,CAAC,EAAE,SAAS,EAAE,GAAG,OAAO,EAAE,oBAC1B,6LAAC;QACC,KAAK;QACL,WAAW,CAAA,GAAA,sHAAA,CAAA,KAAE,AAAD,EAAE,8BAA8B;QAC3C,GAAG,KAAK;;;;;;;AAGb,WAAW,WAAW,GAAG","debugId":null}},
    {"offset": {"line": 110, "column": 0}, "map": {"version":3,"sources":["file:///home/user/studio/src/ai/flows/teach-anything.ts"],"sourcesContent":["\n'use server';\n\n/**\n * @fileOverview A general purpose teaching assistant flow.\n *\n * - teachAnything - A function that provides general teaching assistance.\n * - TeachAnythingInput - The input type for the teachAnything function.\n * - TeachAnythingOutput - The return type for the teachAnything function.\n */\n\nimport {ai} from '@/ai/genkit';\nimport {z} from 'genkit';\n\nconst TeachAnythingInputSchema = z.object({\n  query: z.string().describe('The user\\'s question or request.'),\n});\nexport type TeachAnythingInput = z.infer<typeof TeachAnythingInputSchema>;\n\nconst TeachAnythingOutputSchema = z.object({\n  response: z.string().describe('The AI\\'s response to the user.'),\n});\nexport type TeachAnythingOutput = z.infer<typeof TeachAnythingOutputSchema>;\n\nexport async function teachAnything(input: TeachAnythingInput): Promise<TeachAnythingOutput> {\n  return teachAnythingFlow(input);\n}\n\nconst prompt = ai.definePrompt({\n  name: 'teachAnythingPrompt',\n  input: {schema: TeachAnythingInputSchema},\n  output: {schema: TeachAnythingOutputSchema},\n  prompt: `You are Sahayak, a helpful AI teaching assistant for educators in India. Your goal is to provide concise, practical, and helpful responses to teacher's questions. You can help with lesson planning, classroom management strategies, creating educational content, and student engagement techniques.\n\nUser prompt: {{{query}}}`,\n});\n\nconst teachAnythingFlow = ai.defineFlow(\n  {\n    name: 'teachAnythingFlow',\n    inputSchema: TeachAnythingInputSchema,\n    outputSchema: TeachAnythingOutputSchema,\n  },\n  async input => {\n    const {output} = await prompt(input);\n    return output!;\n  }\n);\n"],"names":[],"mappings":";;;;;;IAwBsB,gBAAA,WAAA,GAAA,CAAA,GAAA,yNAAA,CAAA,wBAAA,EAAA,8CAAA,yNAAA,CAAA,aAAA,EAAA,KAAA,GAAA,yNAAA,CAAA,mBAAA,EAAA","debugId":null}},
    {"offset": {"line": 126, "column": 0}, "map": {"version":3,"sources":["file:///home/user/studio/src/components/icons.tsx"],"sourcesContent":["import type { SVGProps } from \"react\";\n\nexport function SahayakLogo(props: SVGProps<SVGSVGElement>) {\n    return (\n        <svg\n            xmlns=\"http://www.w3.org/2000/svg\"\n            viewBox=\"0 0 256 256\"\n            {...props}\n        >\n            <rect width=\"256\" height=\"256\" fill=\"none\" />\n            <path\n                d=\"M128,24a104,104,0,1,0,104,104A104.2,104.2,0,0,0,128,24Zm33.4,62.6-40,40a8,8,0,0,1-11.3,0l-40-40a8,8,0,0,1,11.3-11.3L128,121.4l34.7-34.7a8,8,0,0,1,11.3,11.3Z\"\n                fill=\"currentColor\"\n                className=\"text-primary\"\n            />\n            <path\n                d=\"M128,152a72,72,0,0,0-58.4,28.3,8,8,0,0,0,10.1,12.4,56,56,0,0,1,96.6,0,8,8,0,0,0,10.1-12.4A72,72,0,0,0,128,152Z\"\n                fill=\"currentColor\"\n                className=\"text-accent\"\n            />\n        </svg>\n    )\n}\n"],"names":[],"mappings":";;;;;AAEO,SAAS,YAAY,KAA8B;IACtD,qBACI,6LAAC;QACG,OAAM;QACN,SAAQ;QACP,GAAG,KAAK;;0BAET,6LAAC;gBAAK,OAAM;gBAAM,QAAO;gBAAM,MAAK;;;;;;0BACpC,6LAAC;gBACG,GAAE;gBACF,MAAK;gBACL,WAAU;;;;;;0BAEd,6LAAC;gBACG,GAAE;gBACF,MAAK;gBACL,WAAU;;;;;;;;;;;;AAI1B;KApBgB","debugId":null}},
    {"offset": {"line": 183, "column": 0}, "map": {"version":3,"sources":["file:///home/user/studio/src/ai/flows/speech-to-text.ts"],"sourcesContent":["\n'use server';\n\n/**\n * @fileOverview A Genkit flow for transcribing audio to text using Google Cloud Speech-to-Text API.\n * \n * - transcribeAudio - A function that transcribes audio data.\n * - TranscribeAudioInput - The input type for the transcribeAudio function.\n * - TranscribeAudioOutput - The return type for the transcribeAudio function.\n */\n\nimport { ai } from '@/ai/genkit';\nimport { z } from 'genkit';\nimport { SpeechClient } from '@google-cloud/speech';\n\nconst TranscribeAudioInputSchema = z.object({\n  audioDataUri: z\n    .string()\n    .describe(\n      \"The audio data to transcribe, as a data URI. Expected format: 'data:audio/webm;codecs=opus;base64,<encoded_data>'.\"\n    ),\n  languageCode: z.string().optional().default('en-IN').describe('The language of the audio.'),\n});\nexport type TranscribeAudioInput = z.infer<typeof TranscribeAudioInputSchema>;\n\nconst TranscribeAudioOutputSchema = z.object({\n  transcription: z.string().describe('The transcribed text.'),\n});\nexport type TranscribeAudioOutput = z.infer<typeof TranscribeAudioOutputSchema>;\n\n// Initialize the SpeechClient.\n// The client will automatically use the project's service account credentials\n// when deployed on Firebase App Hosting. For local development, ensure you have\n// authenticated with `gcloud auth application-default login`.\nlet speechClient: SpeechClient | undefined;\ntry {\n  speechClient = new SpeechClient();\n} catch (e) {\n  console.warn(\"SpeechClient failed to initialize. Voice input may not work in local development if ADC is not configured. It will work when deployed.\", e);\n}\n\n\nexport async function transcribeAudio(\n  input: TranscribeAudioInput\n): Promise<TranscribeAudioOutput> {\n  return transcribeAudioFlow(input);\n}\n\nconst transcribeAudioFlow = ai.defineFlow(\n  {\n    name: 'transcribeAudioFlow',\n    inputSchema: TranscribeAudioInputSchema,\n    outputSchema: TranscribeAudioOutputSchema,\n  },\n  async ({ audioDataUri, languageCode }) => {\n    if (!speechClient) {\n        throw new Error(\"SpeechClient not initialized. This feature may only be available when deployed.\");\n    }\n      \n    // The base64 data is the part of the data URI after the comma\n    const audioBytes = audioDataUri.split(',')[1];\n\n    const audio = {\n      content: audioBytes,\n    };\n    \n    // Note: The 'chirp' model used here is part of the v2 API features,\n    // but the Node.js client can access it via the v1p1beta1 endpoint.\n    const config = {\n      model: 'chirp',\n      encoding: 'WEBM_OPUS' as const,\n      sampleRateHertz: 48000, // This must match the client recording settings\n      languageCode: languageCode,\n    };\n\n    const request = {\n      audio: audio,\n      config: config,\n    };\n\n    try {\n      const [response] = await speechClient.recognize(request);\n      const transcription =\n        response.results\n          ?.map((result) => result.alternatives?.[0].transcript)\n          .join('\\n') || '';\n\n      return { transcription };\n    } catch (error) {\n        console.error('Speech-to-text API error:', error);\n        throw new Error('Failed to transcribe audio.');\n    }\n  }\n);\n"],"names":[],"mappings":";;;;;;IA0CsB,kBAAA,WAAA,GAAA,CAAA,GAAA,yNAAA,CAAA,wBAAA,EAAA,8CAAA,yNAAA,CAAA,aAAA,EAAA,KAAA,GAAA,yNAAA,CAAA,mBAAA,EAAA","debugId":null}},
    {"offset": {"line": 199, "column": 0}, "map": {"version":3,"sources":["file:///home/user/studio/src/components/voice-input.tsx"],"sourcesContent":["\n\"use client\";\n\nimport { useState } from 'react';\nimport { useReactMediaRecorder } from 'react-media-recorder';\nimport { Button } from '@/components/ui/button';\nimport { Mic, Loader2, StopCircle } from 'lucide-react';\nimport { useToast } from '@/hooks/use-toast';\nimport { transcribeAudio } from '@/ai/flows/speech-to-text';\n\ninterface VoiceInputProps {\n  onTranscript: (transcript: string) => void;\n  language?: string;\n  className?: string;\n}\n\nconst fileToDataUri = (blob: Blob): Promise<string> => {\n    return new Promise((resolve, reject) => {\n      const reader = new FileReader();\n      reader.onloadend = () => {\n        if (typeof reader.result === 'string') {\n          resolve(reader.result);\n        } else {\n          reject(new Error('Failed to convert blob to Data URI'));\n        }\n      };\n      reader.onerror = reject;\n      reader.readAsDataURL(blob);\n    });\n};\n\nexport function VoiceInput({ onTranscript, language = 'en-IN', className }: VoiceInputProps) {\n  const [isTranscribing, setIsTranscribing] = useState(false);\n  const { toast } = useToast();\n\n  const handleAudioStop = async (blobUrl: string, blob: Blob) => {\n    setIsTranscribing(true);\n    try {\n      const audioDataUri = await fileToDataUri(blob);\n      \n      const result = await transcribeAudio({ audioDataUri, languageCode: language });\n      \n      if (result.transcription) {\n        onTranscript(result.transcription);\n      } else {\n        toast({\n          variant: 'destructive',\n          title: 'Transcription Failed',\n          description: 'Could not understand audio. Please try again.',\n        });\n      }\n    } catch (error) {\n      console.error('Voice input error:', error);\n      toast({\n        variant: 'destructive',\n        title: 'Voice Error',\n        description: 'Failed to process audio. Please check permissions and try again.',\n      });\n    } finally {\n      setIsTranscribing(false);\n      clearBlobUrl();\n    }\n  };\n\n  const {\n    status,\n    startRecording,\n    stopRecording,\n    clearBlobUrl,\n  } = useReactMediaRecorder({ \n    audio: {\n        channelCount: 1,\n    },\n    onStop: handleAudioStop,\n    onPermissionDenied: () => {\n        toast({\n            variant: \"destructive\",\n            title: \"Microphone Permission Denied\",\n            description: \"Please allow microphone access in your browser settings to use this feature.\"\n        })\n    }\n  });\n\n  return (\n    <Button\n      type=\"button\"\n      size=\"icon\"\n      className={`rounded-full ${className}`}\n      onClick={status === 'recording' ? stopRecording : startRecording}\n      disabled={isTranscribing}\n    >\n      {isTranscribing ? (\n        <Loader2 className=\"animate-spin\" />\n      ) : status === 'recording' ? (\n        <StopCircle className=\"text-destructive\" />\n      ) : (\n        <Mic />\n      )}\n    </Button>\n  );\n};\n"],"names":[],"mappings":";;;;AAGA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;;;AAPA;;;;;;;AAeA,MAAM,gBAAgB,CAAC;IACnB,OAAO,IAAI,QAAQ,CAAC,SAAS;QAC3B,MAAM,SAAS,IAAI;QACnB,OAAO,SAAS,GAAG;YACjB,IAAI,OAAO,OAAO,MAAM,KAAK,UAAU;gBACrC,QAAQ,OAAO,MAAM;YACvB,OAAO;gBACL,OAAO,IAAI,MAAM;YACnB;QACF;QACA,OAAO,OAAO,GAAG;QACjB,OAAO,aAAa,CAAC;IACvB;AACJ;AAEO,SAAS,WAAW,EAAE,YAAY,EAAE,WAAW,OAAO,EAAE,SAAS,EAAmB;;IACzF,MAAM,CAAC,gBAAgB,kBAAkB,GAAG,CAAA,GAAA,6JAAA,CAAA,WAAQ,AAAD,EAAE;IACrD,MAAM,EAAE,KAAK,EAAE,GAAG,CAAA,GAAA,+HAAA,CAAA,WAAQ,AAAD;IAEzB,MAAM,kBAAkB,OAAO,SAAiB;QAC9C,kBAAkB;QAClB,IAAI;YACF,MAAM,eAAe,MAAM,cAAc;YAEzC,MAAM,SAAS,MAAM,CAAA,GAAA,6JAAA,CAAA,kBAAe,AAAD,EAAE;gBAAE;gBAAc,cAAc;YAAS;YAE5E,IAAI,OAAO,aAAa,EAAE;gBACxB,aAAa,OAAO,aAAa;YACnC,OAAO;gBACL,MAAM;oBACJ,SAAS;oBACT,OAAO;oBACP,aAAa;gBACf;YACF;QACF,EAAE,OAAO,OAAO;YACd,QAAQ,KAAK,CAAC,sBAAsB;YACpC,MAAM;gBACJ,SAAS;gBACT,OAAO;gBACP,aAAa;YACf;QACF,SAAU;YACR,kBAAkB;YAClB;QACF;IACF;IAEA,MAAM,EACJ,MAAM,EACN,cAAc,EACd,aAAa,EACb,YAAY,EACb,GAAG,CAAA,GAAA,sJAAA,CAAA,wBAAqB,AAAD,EAAE;QACxB,OAAO;YACH,cAAc;QAClB;QACA,QAAQ;QACR,kBAAkB;gDAAE;gBAChB,MAAM;oBACF,SAAS;oBACT,OAAO;oBACP,aAAa;gBACjB;YACJ;;IACF;IAEA,qBACE,6LAAC,qIAAA,CAAA,SAAM;QACL,MAAK;QACL,MAAK;QACL,WAAW,CAAC,aAAa,EAAE,WAAW;QACtC,SAAS,WAAW,cAAc,gBAAgB;QAClD,UAAU;kBAET,+BACC,6LAAC,oNAAA,CAAA,UAAO;YAAC,WAAU;;;;;mBACjB,WAAW,4BACb,6LAAC,qNAAA,CAAA,aAAU;YAAC,WAAU;;;;;iCAEtB,6LAAC,mMAAA,CAAA,MAAG;;;;;;;;;;AAIZ;GArEgB;;QAEI,+HAAA,CAAA,WAAQ;QAoCtB,sJAAA,CAAA,wBAAqB;;;KAtCX","debugId":null}},
    {"offset": {"line": 329, "column": 0}, "map": {"version":3,"sources":["file:///home/user/studio/src/ai/flows/text-to-speech.ts"],"sourcesContent":["\n'use server';\n\n/**\n * @fileOverview A Genkit flow for synthesizing text into speech.\n * \n * - synthesizeSpeech - A function that converts text to audio.\n * - SynthesizeSpeechInput - The input type for the synthesizeSpeech function.\n * - SynthesizeSpeechOutput - The return type for the synthesizeSpeech function.\n */\n\nimport { ai } from '@/ai/genkit';\nimport { z } from 'genkit';\nimport wav from 'wav';\nimport { googleAI } from '@genkit-ai/googleai';\n\n\nconst SynthesizeSpeechInputSchema = z.object({\n  text: z.string().describe('The text to synthesize.'),\n  languageCode: z.string().optional().default('en-IN').describe('The language for the speech.'),\n});\nexport type SynthesizeSpeechInput = z.infer<typeof SynthesizeSpeechInputSchema>;\n\nconst SynthesizeSpeechOutputSchema = z.object({\n    audioDataUri: z.string().describe(\"The synthesized audio as a data URI. Expected format: 'data:audio/wav;base64,<encoded_data>'.\"),\n});\nexport type SynthesizeSpeechOutput = z.infer<typeof SynthesizeSpeechOutputSchema>;\n\n\nexport async function synthesizeSpeech(\n  input: SynthesizeSpeechInput\n): Promise<SynthesizeSpeechOutput> {\n  return synthesizeSpeechFlow(input);\n}\n\nasync function toWav(\n  pcmData: Buffer,\n  channels = 1,\n  rate = 24000,\n  sampleWidth = 2\n): Promise<string> {\n  return new Promise((resolve, reject) => {\n    const writer = new wav.Writer({\n      channels,\n      sampleRate: rate,\n      bitDepth: sampleWidth * 8,\n    });\n\n    let bufs: any[] = [];\n    writer.on('error', reject);\n    writer.on('data', function (d) {\n      bufs.push(d);\n    });\n    writer.on('end', function () {\n      resolve(Buffer.concat(bufs).toString('base64'));\n    });\n\n    writer.write(pcmData);\n    writer.end();\n  });\n}\n\nconst synthesizeSpeechFlow = ai.defineFlow(\n  {\n    name: 'synthesizeSpeechFlow',\n    inputSchema: SynthesizeSpeechInputSchema,\n    outputSchema: SynthesizeSpeechOutputSchema,\n  },\n  async ({ text }) => {\n    if (!text) {\n        return { audioDataUri: '' };\n    }\n\n    try {\n        const { media } = await ai.generate({\n            model: googleAI.model('gemini-2.5-flash-preview-tts'),\n            config: {\n                responseModalities: ['AUDIO'],\n                speechConfig: {\n                voiceConfig: {\n                    prebuiltVoiceConfig: { voiceName: 'Algenib' },\n                },\n                },\n            },\n            prompt: text.substring(0, 5000), // Enforce a character limit\n        });\n\n        if (!media) {\n            throw new Error('No audio media returned from TTS model.');\n        }\n\n        const audioBuffer = Buffer.from(\n            media.url.substring(media.url.indexOf(',') + 1),\n            'base64'\n        );\n        \n        const wavBase64 = await toWav(audioBuffer);\n\n        return {\n            audioDataUri: 'data:audio/wav;base64,' + wavBase64,\n        };\n    } catch (error) {\n        console.error('Text-to-speech API error:', error);\n        throw new Error('Failed to synthesize speech.');\n    }\n  }\n);\n"],"names":[],"mappings":";;;;;;IA6BsB,mBAAA,WAAA,GAAA,CAAA,GAAA,yNAAA,CAAA,wBAAA,EAAA,8CAAA,yNAAA,CAAA,aAAA,EAAA,KAAA,GAAA,yNAAA,CAAA,mBAAA,EAAA","debugId":null}},
    {"offset": {"line": 345, "column": 0}, "map": {"version":3,"sources":["file:///home/user/studio/src/components/voice-output.tsx"],"sourcesContent":["\n\"use client\";\n\nimport React, { useState, useEffect, useRef } from 'react';\nimport { Button } from '@/components/ui/button';\nimport { Speaker, Loader2, StopCircle } from 'lucide-react';\nimport { useToast } from '@/hooks/use-toast';\nimport { synthesizeSpeech } from '@/ai/flows/text-to-speech';\nimport { cn } from '@/lib/utils';\n\ninterface VoiceOutputProps {\n  text: string;\n  language?: string;\n  className?: string;\n}\n\nexport function VoiceOutput({ text, language = 'en-IN', className }: VoiceOutputProps) {\n  const [isPlaying, setIsPlaying] = useState(false);\n  const [isGenerating, setIsGenerating] = useState(false);\n  const audioRef = useRef<HTMLAudioElement | null>(null);\n  const { toast } = useToast();\n\n  useEffect(() => {\n    // Cleanup audio on component unmount\n    return () => {\n      if (audioRef.current) {\n        audioRef.current.pause();\n        audioRef.current = null;\n      }\n    };\n  }, []);\n\n  const playAudio = async () => {\n    if (!text) return;\n    \n    // If already playing, stop it\n    if (isPlaying && audioRef.current) {\n        audioRef.current.pause();\n        audioRef.current.currentTime = 0;\n        setIsPlaying(false);\n        return;\n    }\n    \n    setIsGenerating(true);\n    \n    try {\n      const result = await synthesizeSpeech({ text, languageCode: language });\n      \n      if (result.audioDataUri) {\n        const audio = new Audio(result.audioDataUri);\n        audioRef.current = audio;\n        \n        setIsPlaying(true);\n        audio.play();\n        \n        audio.onended = () => {\n          setIsPlaying(false);\n          audioRef.current = null;\n        };\n        \n        audio.onerror = () => {\n          setIsPlaying(false);\n          audioRef.current = null;\n           toast({\n            variant: 'destructive',\n            title: 'Audio Error',\n            description: 'Could not play the generated audio.',\n          });\n        };\n      } else {\n         toast({\n            variant: 'destructive',\n            title: 'Audio Generation Failed',\n            description: 'The audio could not be generated for this text.',\n         });\n      }\n    } catch (error) {\n      console.error('TTS Error:', error);\n       toast({\n        variant: 'destructive',\n        title: 'TTS Error',\n        description: 'An unexpected error occurred while generating speech.',\n      });\n    } finally {\n      setIsGenerating(false);\n    }\n  };\n\n  return (\n    <Button\n      type=\"button\"\n      variant=\"ghost\"\n      size=\"icon\"\n      onClick={playAudio}\n      disabled={isGenerating || !text}\n      className={cn(\"rounded-full\", className)}\n    >\n      {isGenerating ? (\n        <Loader2 className=\"animate-spin\" />\n      ) : isPlaying ? (\n        <StopCircle className=\"text-primary\" />\n      ) : (\n        <Speaker />\n      )}\n    </Button>\n  );\n};\n"],"names":[],"mappings":";;;;AAGA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;;;AAPA;;;;;;;AAeO,SAAS,YAAY,EAAE,IAAI,EAAE,WAAW,OAAO,EAAE,SAAS,EAAoB;;IACnF,MAAM,CAAC,WAAW,aAAa,GAAG,CAAA,GAAA,6JAAA,CAAA,WAAQ,AAAD,EAAE;IAC3C,MAAM,CAAC,cAAc,gBAAgB,GAAG,CAAA,GAAA,6JAAA,CAAA,WAAQ,AAAD,EAAE;IACjD,MAAM,WAAW,CAAA,GAAA,6JAAA,CAAA,SAAM,AAAD,EAA2B;IACjD,MAAM,EAAE,KAAK,EAAE,GAAG,CAAA,GAAA,+HAAA,CAAA,WAAQ,AAAD;IAEzB,CAAA,GAAA,6JAAA,CAAA,YAAS,AAAD;iCAAE;YACR,qCAAqC;YACrC;yCAAO;oBACL,IAAI,SAAS,OAAO,EAAE;wBACpB,SAAS,OAAO,CAAC,KAAK;wBACtB,SAAS,OAAO,GAAG;oBACrB;gBACF;;QACF;gCAAG,EAAE;IAEL,MAAM,YAAY;QAChB,IAAI,CAAC,MAAM;QAEX,8BAA8B;QAC9B,IAAI,aAAa,SAAS,OAAO,EAAE;YAC/B,SAAS,OAAO,CAAC,KAAK;YACtB,SAAS,OAAO,CAAC,WAAW,GAAG;YAC/B,aAAa;YACb;QACJ;QAEA,gBAAgB;QAEhB,IAAI;YACF,MAAM,SAAS,MAAM,CAAA,GAAA,6JAAA,CAAA,mBAAgB,AAAD,EAAE;gBAAE;gBAAM,cAAc;YAAS;YAErE,IAAI,OAAO,YAAY,EAAE;gBACvB,MAAM,QAAQ,IAAI,MAAM,OAAO,YAAY;gBAC3C,SAAS,OAAO,GAAG;gBAEnB,aAAa;gBACb,MAAM,IAAI;gBAEV,MAAM,OAAO,GAAG;oBACd,aAAa;oBACb,SAAS,OAAO,GAAG;gBACrB;gBAEA,MAAM,OAAO,GAAG;oBACd,aAAa;oBACb,SAAS,OAAO,GAAG;oBAClB,MAAM;wBACL,SAAS;wBACT,OAAO;wBACP,aAAa;oBACf;gBACF;YACF,OAAO;gBACJ,MAAM;oBACH,SAAS;oBACT,OAAO;oBACP,aAAa;gBAChB;YACH;QACF,EAAE,OAAO,OAAO;YACd,QAAQ,KAAK,CAAC,cAAc;YAC3B,MAAM;gBACL,SAAS;gBACT,OAAO;gBACP,aAAa;YACf;QACF,SAAU;YACR,gBAAgB;QAClB;IACF;IAEA,qBACE,6LAAC,qIAAA,CAAA,SAAM;QACL,MAAK;QACL,SAAQ;QACR,MAAK;QACL,SAAS;QACT,UAAU,gBAAgB,CAAC;QAC3B,WAAW,CAAA,GAAA,sHAAA,CAAA,KAAE,AAAD,EAAE,gBAAgB;kBAE7B,6BACC,6LAAC,oNAAA,CAAA,UAAO;YAAC,WAAU;;;;;mBACjB,0BACF,6LAAC,qNAAA,CAAA,aAAU;YAAC,WAAU;;;;;iCAEtB,6LAAC,2MAAA,CAAA,UAAO;;;;;;;;;;AAIhB;GA1FgB;;QAII,+HAAA,CAAA,WAAQ;;;KAJZ","debugId":null}},
    {"offset": {"line": 483, "column": 0}, "map": {"version":3,"sources":["file:///home/user/studio/src/app/dashboard-client.tsx"],"sourcesContent":["\n\"use client\";\n\nimport { useState } from \"react\";\nimport { useRouter } from \"next/navigation\";\nimport { Send, Loader2, Mic, StopCircle, Speaker } from \"lucide-react\";\nimport { Button } from \"@/components/ui/button\";\nimport { Input } from \"@/components/ui/input\";\nimport { Card, CardContent } from \"@/components/ui/card\";\nimport { teachAnything } from \"@/ai/flows/teach-anything\";\nimport { SahayakLogo } from \"@/components/icons\";\nimport { VoiceInput } from \"@/components/voice-input\";\nimport { VoiceOutput } from \"@/components/voice-output\";\n\nconst suggestionPrompts = [\n  {\n    title: \"Create a worksheet\",\n    prompt: \"Create a math worksheet for grade 5 on multiplication\",\n    feature: \"worksheets\"\n  },\n  {\n    title: \"Generate a quiz\",\n    prompt: \"Generate a science quiz about photosynthesis for grade 7\",\n    feature: \"games\"\n  },\n  {\n    title: \"Make a visual aid\",\n    prompt: \"Make a visual aid showing the water cycle\",\n    feature: \"visual-aids\"\n  },\n  {\n    title: \"Design a game\",\n    prompt: \"Design a word scramble game for vocabulary about animals\",\n    feature: \"games\"\n  },\n];\n\nconst featureKeywords: Record<string, string[]> = {\n  worksheets: ['worksheet', 'exercise', 'practice sheet'],\n  games: ['game', 'quiz', 'bingo', 'riddle', 'scramble', 'true/false', 'fill-in-the-blanks'],\n  'visual-aids': ['visual', 'chart', 'diagram', 'image', 'drawing', 'table'],\n  'knowledge-base': ['explain', 'what is', 'how do', 'why is'],\n  'generate-content': ['story', 'poem', 'dialogue', 'write a'],\n};\n\ninterface Message {\n  id: number;\n  text: string;\n  isUser: boolean;\n}\n\nexport function DashboardClient() {\n  const router = useRouter();\n  const [messages, setMessages] = useState<Message[]>([]);\n  const [prompt, setPrompt] = useState(\"\");\n  const [isLoading, setIsLoading] = useState(false);\n\n  const detectFeature = (text: string) => {\n    const lowerText = text.toLowerCase();\n    for (const feature in featureKeywords) {\n      for (const keyword of featureKeywords[feature]) {\n        if (lowerText.includes(keyword)) {\n          return feature;\n        }\n      }\n    }\n    return null;\n  };\n  \n  const redirectToFeature = (feature: string, promptText: string) => {\n    const params = new URLSearchParams();\n    \n    switch (feature) {\n      case 'worksheets':\n        // Simple parsing, can be improved\n        const gradeMatch = promptText.match(/grade (\\d+)/i);\n        const topicMatch = promptText.match(/(on|about) (.*)/i);\n        if (gradeMatch) params.set('grade', `Grade ${gradeMatch[1]}`);\n        if (topicMatch) params.set('lessonTopic', topicMatch[2]);\n        params.set('mode', 'manual');\n        router.push(`/worksheets?${params.toString()}`);\n        break;\n      case 'games':\n        const gameGradeMatch = promptText.match(/grade (\\d+)/i);\n        const gameTopicMatch = promptText.match(/(on|about) ([\\w\\s]+)/i);\n        const gameTypeMatch = promptText.match(/(quiz|bingo|riddle|scramble|true\\/false|fill-in-the-blanks)/i);\n\n        if (gameGradeMatch) params.set('grade', gameGradeMatch[1]);\n        if (gameTopicMatch) params.set('topic', gameTopicMatch[2].split(\" for\")[0].trim());\n        if(gameTypeMatch) params.set('gameType', gameTypeMatch[1]);\n        router.push(`/games?${params.toString()}`);\n        break;\n      case 'visual-aids':\n        params.set('description', promptText);\n        router.push(`/visual-aids?${params.toString()}`);\n        break;\n      default:\n         router.push(`/${feature}`);\n    }\n  };\n\n  const processPrompt = async (promptText: string) => {\n    if (!promptText.trim()) return;\n\n    setIsLoading(true);\n    setMessages(prev => [...prev, { id: Date.now(), text: promptText, isUser: true }]);\n    setPrompt(\"\");\n    \n    const matchedFeature = detectFeature(promptText);\n\n    if (matchedFeature) {\n        redirectToFeature(matchedFeature, promptText);\n        // No need to set loading to false here as we are navigating away\n        return;\n    }\n\n    // If no specific feature, use the general AI assistant\n    try {\n      const result = await teachAnything({ query: promptText });\n      setMessages(prev => [...prev, { id: Date.now() + 1, text: result.response, isUser: false }]);\n    } catch (error) {\n      console.error(\"AI chat error:\", error);\n      setMessages(prev => [...prev, { id: Date.now() + 1, text: \"Sorry, I ran into a problem. Please try again.\", isUser: false }]);\n    } finally {\n      setIsLoading(false);\n    }\n  };\n\n  const handleVoiceTranscript = (transcript: string) => {\n    setPrompt(transcript);\n  };\n\n  return (\n    <div className=\"flex flex-col h-full w-full max-w-4xl mx-auto\">\n      <div className=\"flex-1 pb-24\">\n        {messages.length === 0 ? (\n          <div className=\"text-center py-12\">\n            <h1 className=\"text-4xl font-bold font-headline mb-4\">Salute, Super Teacher! 👋</h1>\n            <p className=\"text-muted-foreground text-lg\">How can I assist you with your teaching today?</p>\n            <div className=\"grid grid-cols-1 md:grid-cols-2 gap-4 mt-12\">\n              {suggestionPrompts.map((p) => (\n                <Card \n                    key={p.title} \n                    className=\"p-4 text-left hover:bg-muted cursor-pointer transition-colors\"\n                >\n                    <CardContent className=\"p-0\" onClick={() => redirectToFeature(p.feature, p.prompt)}>\n                      <h3 className=\"font-semibold\">{p.title}</h3>\n                      <p className=\"text-sm text-muted-foreground\">{p.prompt}</p>\n                    </CardContent>\n                    <div className=\"flex justify-end mt-2\">\n                      <VoiceOutput text={p.prompt} />\n                    </div>\n                </Card>\n              ))}\n            </div>\n          </div>\n        ) : (\n          <div className=\"space-y-6 pt-4\">\n            {messages.map((msg) => (\n              <div key={msg.id} className={`flex ${msg.isUser ? 'justify-end' : 'justify-start'}`}>\n                {!msg.isUser && <SahayakLogo className=\"w-8 h-8 mr-2 shrink-0\" />}\n                <div className={`px-4 py-3 rounded-2xl max-w-xl group relative ${msg.isUser ? 'bg-primary text-primary-foreground rounded-br-none' : 'bg-muted rounded-bl-none'}`}>\n                  <pre className=\"whitespace-pre-wrap font-body text-base\">{msg.text}</pre>\n                   {!msg.isUser && (\n                     <VoiceOutput text={msg.text} className=\"absolute -bottom-4 -right-4\" />\n                   )}\n                </div>\n              </div>\n            ))}\n            {isLoading && (\n               <div className=\"flex justify-start\">\n                 <SahayakLogo className=\"w-8 h-8 mr-2 shrink-0\" />\n                 <div className=\"px-4 py-3 rounded-2xl max-w-xl bg-muted rounded-bl-none flex items-center\">\n                    <Loader2 className=\"h-5 w-5 animate-spin\"/>\n                 </div>\n               </div>\n            )}\n          </div>\n        )}\n      </div>\n      \n      <div className=\"fixed bottom-0 right-0 left-0 md:left-[14rem] bg-background/80 backdrop-blur-sm\">\n        <div className=\"max-w-4xl mx-auto px-4 py-4\">\n          <div className=\"relative\">\n            <Input\n              type=\"text\"\n              placeholder=\"Ask me anything about teaching...\"\n              value={prompt}\n              onChange={(e) => setPrompt(e.target.value)}\n              onKeyDown={(e) => { if (e.key === 'Enter') processPrompt(prompt); }}\n              className=\"w-full p-6 border rounded-full focus:outline-none focus:ring-2 focus:ring-primary pr-24\"\n              disabled={isLoading}\n            />\n            <div className=\"absolute right-2.5 top-1/2 -translate-y-1/2 flex items-center gap-1\">\n              <VoiceInput onTranscript={handleVoiceTranscript} />\n              <Button\n                size=\"icon\"\n                className=\"rounded-full\"\n                onClick={() => processPrompt(prompt)}\n                disabled={isLoading || !prompt.trim()}\n              >\n                {isLoading ? <Loader2 className=\"animate-spin\" /> : <Send />}\n              </Button>\n            </div>\n          </div>\n        </div>\n      </div>\n    </div>\n  );\n}\n"],"names":[],"mappings":";;;;AAGA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AAXA;;;;;;;;;;;AAaA,MAAM,oBAAoB;IACxB;QACE,OAAO;QACP,QAAQ;QACR,SAAS;IACX;IACA;QACE,OAAO;QACP,QAAQ;QACR,SAAS;IACX;IACA;QACE,OAAO;QACP,QAAQ;QACR,SAAS;IACX;IACA;QACE,OAAO;QACP,QAAQ;QACR,SAAS;IACX;CACD;AAED,MAAM,kBAA4C;IAChD,YAAY;QAAC;QAAa;QAAY;KAAiB;IACvD,OAAO;QAAC;QAAQ;QAAQ;QAAS;QAAU;QAAY;QAAc;KAAqB;IAC1F,eAAe;QAAC;QAAU;QAAS;QAAW;QAAS;QAAW;KAAQ;IAC1E,kBAAkB;QAAC;QAAW;QAAW;QAAU;KAAS;IAC5D,oBAAoB;QAAC;QAAS;QAAQ;QAAY;KAAU;AAC9D;AAQO,SAAS;;IACd,MAAM,SAAS,CAAA,GAAA,qIAAA,CAAA,YAAS,AAAD;IACvB,MAAM,CAAC,UAAU,YAAY,GAAG,CAAA,GAAA,6JAAA,CAAA,WAAQ,AAAD,EAAa,EAAE;IACtD,MAAM,CAAC,QAAQ,UAAU,GAAG,CAAA,GAAA,6JAAA,CAAA,WAAQ,AAAD,EAAE;IACrC,MAAM,CAAC,WAAW,aAAa,GAAG,CAAA,GAAA,6JAAA,CAAA,WAAQ,AAAD,EAAE;IAE3C,MAAM,gBAAgB,CAAC;QACrB,MAAM,YAAY,KAAK,WAAW;QAClC,IAAK,MAAM,WAAW,gBAAiB;YACrC,KAAK,MAAM,WAAW,eAAe,CAAC,QAAQ,CAAE;gBAC9C,IAAI,UAAU,QAAQ,CAAC,UAAU;oBAC/B,OAAO;gBACT;YACF;QACF;QACA,OAAO;IACT;IAEA,MAAM,oBAAoB,CAAC,SAAiB;QAC1C,MAAM,SAAS,IAAI;QAEnB,OAAQ;YACN,KAAK;gBACH,kCAAkC;gBAClC,MAAM,aAAa,WAAW,KAAK,CAAC;gBACpC,MAAM,aAAa,WAAW,KAAK,CAAC;gBACpC,IAAI,YAAY,OAAO,GAAG,CAAC,SAAS,CAAC,MAAM,EAAE,UAAU,CAAC,EAAE,EAAE;gBAC5D,IAAI,YAAY,OAAO,GAAG,CAAC,eAAe,UAAU,CAAC,EAAE;gBACvD,OAAO,GAAG,CAAC,QAAQ;gBACnB,OAAO,IAAI,CAAC,CAAC,YAAY,EAAE,OAAO,QAAQ,IAAI;gBAC9C;YACF,KAAK;gBACH,MAAM,iBAAiB,WAAW,KAAK,CAAC;gBACxC,MAAM,iBAAiB,WAAW,KAAK,CAAC;gBACxC,MAAM,gBAAgB,WAAW,KAAK,CAAC;gBAEvC,IAAI,gBAAgB,OAAO,GAAG,CAAC,SAAS,cAAc,CAAC,EAAE;gBACzD,IAAI,gBAAgB,OAAO,GAAG,CAAC,SAAS,cAAc,CAAC,EAAE,CAAC,KAAK,CAAC,OAAO,CAAC,EAAE,CAAC,IAAI;gBAC/E,IAAG,eAAe,OAAO,GAAG,CAAC,YAAY,aAAa,CAAC,EAAE;gBACzD,OAAO,IAAI,CAAC,CAAC,OAAO,EAAE,OAAO,QAAQ,IAAI;gBACzC;YACF,KAAK;gBACH,OAAO,GAAG,CAAC,eAAe;gBAC1B,OAAO,IAAI,CAAC,CAAC,aAAa,EAAE,OAAO,QAAQ,IAAI;gBAC/C;YACF;gBACG,OAAO,IAAI,CAAC,CAAC,CAAC,EAAE,SAAS;QAC9B;IACF;IAEA,MAAM,gBAAgB,OAAO;QAC3B,IAAI,CAAC,WAAW,IAAI,IAAI;QAExB,aAAa;QACb,YAAY,CAAA,OAAQ;mBAAI;gBAAM;oBAAE,IAAI,KAAK,GAAG;oBAAI,MAAM;oBAAY,QAAQ;gBAAK;aAAE;QACjF,UAAU;QAEV,MAAM,iBAAiB,cAAc;QAErC,IAAI,gBAAgB;YAChB,kBAAkB,gBAAgB;YAClC,iEAAiE;YACjE;QACJ;QAEA,uDAAuD;QACvD,IAAI;YACF,MAAM,SAAS,MAAM,CAAA,GAAA,6JAAA,CAAA,gBAAa,AAAD,EAAE;gBAAE,OAAO;YAAW;YACvD,YAAY,CAAA,OAAQ;uBAAI;oBAAM;wBAAE,IAAI,KAAK,GAAG,KAAK;wBAAG,MAAM,OAAO,QAAQ;wBAAE,QAAQ;oBAAM;iBAAE;QAC7F,EAAE,OAAO,OAAO;YACd,QAAQ,KAAK,CAAC,kBAAkB;YAChC,YAAY,CAAA,OAAQ;uBAAI;oBAAM;wBAAE,IAAI,KAAK,GAAG,KAAK;wBAAG,MAAM;wBAAkD,QAAQ;oBAAM;iBAAE;QAC9H,SAAU;YACR,aAAa;QACf;IACF;IAEA,MAAM,wBAAwB,CAAC;QAC7B,UAAU;IACZ;IAEA,qBACE,6LAAC;QAAI,WAAU;;0BACb,6LAAC;gBAAI,WAAU;0BACZ,SAAS,MAAM,KAAK,kBACnB,6LAAC;oBAAI,WAAU;;sCACb,6LAAC;4BAAG,WAAU;sCAAwC;;;;;;sCACtD,6LAAC;4BAAE,WAAU;sCAAgC;;;;;;sCAC7C,6LAAC;4BAAI,WAAU;sCACZ,kBAAkB,GAAG,CAAC,CAAC,kBACtB,6LAAC,mIAAA,CAAA,OAAI;oCAED,WAAU;;sDAEV,6LAAC,mIAAA,CAAA,cAAW;4CAAC,WAAU;4CAAM,SAAS,IAAM,kBAAkB,EAAE,OAAO,EAAE,EAAE,MAAM;;8DAC/E,6LAAC;oDAAG,WAAU;8DAAiB,EAAE,KAAK;;;;;;8DACtC,6LAAC;oDAAE,WAAU;8DAAiC,EAAE,MAAM;;;;;;;;;;;;sDAExD,6LAAC;4CAAI,WAAU;sDACb,cAAA,6LAAC,wIAAA,CAAA,cAAW;gDAAC,MAAM,EAAE,MAAM;;;;;;;;;;;;mCARxB,EAAE,KAAK;;;;;;;;;;;;;;;yCAetB,6LAAC;oBAAI,WAAU;;wBACZ,SAAS,GAAG,CAAC,CAAC,oBACb,6LAAC;gCAAiB,WAAW,CAAC,KAAK,EAAE,IAAI,MAAM,GAAG,gBAAgB,iBAAiB;;oCAChF,CAAC,IAAI,MAAM,kBAAI,6LAAC,8HAAA,CAAA,cAAW;wCAAC,WAAU;;;;;;kDACvC,6LAAC;wCAAI,WAAW,CAAC,8CAA8C,EAAE,IAAI,MAAM,GAAG,uDAAuD,4BAA4B;;0DAC/J,6LAAC;gDAAI,WAAU;0DAA2C,IAAI,IAAI;;;;;;4CAChE,CAAC,IAAI,MAAM,kBACV,6LAAC,wIAAA,CAAA,cAAW;gDAAC,MAAM,IAAI,IAAI;gDAAE,WAAU;;;;;;;;;;;;;+BALpC,IAAI,EAAE;;;;;wBAUjB,2BACE,6LAAC;4BAAI,WAAU;;8CACb,6LAAC,8HAAA,CAAA,cAAW;oCAAC,WAAU;;;;;;8CACvB,6LAAC;oCAAI,WAAU;8CACZ,cAAA,6LAAC,oNAAA,CAAA,UAAO;wCAAC,WAAU;;;;;;;;;;;;;;;;;;;;;;;;;;;;0BAQjC,6LAAC;gBAAI,WAAU;0BACb,cAAA,6LAAC;oBAAI,WAAU;8BACb,cAAA,6LAAC;wBAAI,WAAU;;0CACb,6LAAC,oIAAA,CAAA,QAAK;gCACJ,MAAK;gCACL,aAAY;gCACZ,OAAO;gCACP,UAAU,CAAC,IAAM,UAAU,EAAE,MAAM,CAAC,KAAK;gCACzC,WAAW,CAAC;oCAAQ,IAAI,EAAE,GAAG,KAAK,SAAS,cAAc;gCAAS;gCAClE,WAAU;gCACV,UAAU;;;;;;0CAEZ,6LAAC;gCAAI,WAAU;;kDACb,6LAAC,uIAAA,CAAA,aAAU;wCAAC,cAAc;;;;;;kDAC1B,6LAAC,qIAAA,CAAA,SAAM;wCACL,MAAK;wCACL,WAAU;wCACV,SAAS,IAAM,cAAc;wCAC7B,UAAU,aAAa,CAAC,OAAO,IAAI;kDAElC,0BAAY,6LAAC,oNAAA,CAAA,UAAO;4CAAC,WAAU;;;;;iEAAoB,6LAAC,qMAAA,CAAA,OAAI;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAQzE;GA9JgB;;QACC,qIAAA,CAAA,YAAS;;;KADV","debugId":null}}]
}