{
  "version": 3,
  "sources": [],
  "sections": [
    {"offset": {"line": 207, "column": 0}, "map": {"version":3,"sources":["file:///home/user/studio/src/ai/genkit.ts"],"sourcesContent":["import {genkit} from 'genkit';\nimport {googleAI} from '@genkit-ai/googleai';\n\nexport const ai = genkit({\n  plugins: [googleAI()],\n  model: 'googleai/gemini-2.0-flash',\n});\n"],"names":[],"mappings":";;;AAAA;AAAA;AACA;AAAA;;;AAEO,MAAM,KAAK,CAAA,GAAA,uIAAA,CAAA,SAAM,AAAD,EAAE;IACvB,SAAS;QAAC,CAAA,GAAA,2KAAA,CAAA,WAAQ,AAAD;KAAI;IACrB,OAAO;AACT","debugId":null}},
    {"offset": {"line": 228, "column": 0}, "map": {"version":3,"sources":["file:///home/user/studio/src/ai/flows/teach-anything.ts"],"sourcesContent":["\n'use server';\n\n/**\n * @fileOverview A general purpose teaching assistant flow.\n *\n * - teachAnything - A function that provides general teaching assistance.\n * - TeachAnythingInput - The input type for the teachAnything function.\n * - TeachAnythingOutput - The return type for the teachAnything function.\n */\n\nimport {ai} from '@/ai/genkit';\nimport {z} from 'genkit';\nimport { Message } from 'genkit';\n\n\nconst TeachAnythingInputSchema = z.object({\n  history: z.array(z.any()),\n});\nexport type TeachAnythingInput = z.infer<typeof TeachAnythingInputSchema>;\n\nconst TeachAnythingOutputSchema = z.object({\n  response: z.string().describe('The AI\\'s response to the user.'),\n});\nexport type TeachAnythingOutput = z.infer<typeof TeachAnythingOutputSchema>;\n\nexport async function teachAnything(input: TeachAnythingInput): Promise<TeachAnythingOutput> {\n  return teachAnythingFlow(input);\n}\n\n\nconst teachAnythingFlow = ai.defineFlow(\n  {\n    name: 'teachAnythingFlow',\n    inputSchema: TeachAnythingInputSchema,\n    outputSchema: TeachAnythingOutputSchema,\n  },\n  async ({history}) => {\n    const systemPrompt = `You are Sahayak, a helpful AI teaching assistant for educators in India. Your goal is to provide concise, practical, and helpful responses to teacher's questions. You can help with lesson planning, classroom management strategies, creating educational content, and student engagement techniques. Keep your responses short and to the point.`;\n\n    const _messages: Message[] = history.map((msg: any) => ({\n      role: msg.isUser ? 'user' : 'model',\n      content: [{ text: msg.text }],\n    }));\n\n    const { output } = await ai.generate({\n      system: systemPrompt,\n      history: _messages,\n      output: {\n        schema: TeachAnythingOutputSchema\n      }\n    });\n    \n    return output!;\n  }\n);\n"],"names":[],"mappings":";;;;;AAGA;;;;;;CAMC,GAED;AACA;AAAA;;;;;;AAIA,MAAM,2BAA2B,uIAAA,CAAA,IAAC,CAAC,MAAM,CAAC;IACxC,SAAS,uIAAA,CAAA,IAAC,CAAC,KAAK,CAAC,uIAAA,CAAA,IAAC,CAAC,GAAG;AACxB;AAGA,MAAM,4BAA4B,uIAAA,CAAA,IAAC,CAAC,MAAM,CAAC;IACzC,UAAU,uIAAA,CAAA,IAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;AAChC;AAGO,eAAe,cAAc,KAAyB;IAC3D,OAAO,kBAAkB;AAC3B;AAGA,MAAM,oBAAoB,mHAAA,CAAA,KAAE,CAAC,UAAU,CACrC;IACE,MAAM;IACN,aAAa;IACb,cAAc;AAChB,GACA,OAAO,EAAC,OAAO,EAAC;IACd,MAAM,eAAe,CAAC,mVAAmV,CAAC;IAE1W,MAAM,YAAuB,QAAQ,GAAG,CAAC,CAAC,MAAa,CAAC;YACtD,MAAM,IAAI,MAAM,GAAG,SAAS;YAC5B,SAAS;gBAAC;oBAAE,MAAM,IAAI,IAAI;gBAAC;aAAE;QAC/B,CAAC;IAED,MAAM,EAAE,MAAM,EAAE,GAAG,MAAM,mHAAA,CAAA,KAAE,CAAC,QAAQ,CAAC;QACnC,QAAQ;QACR,SAAS;QACT,QAAQ;YACN,QAAQ;QACV;IACF;IAEA,OAAO;AACT;;;IA5BoB;;AAAA,+OAAA","debugId":null}},
    {"offset": {"line": 306, "column": 0}, "map": {"version":3,"sources":["file:///home/user/studio/src/ai/flows/text-to-speech.ts"],"sourcesContent":["\n'use server';\n/**\n * @fileOverview A text-to-speech AI flow.\n *\n * - textToSpeech - A function that converts text to speech.\n * - TextToSpeechInput - The input type for the textToSpeech function.\n * - TextToSpeechOutput - The return type for the textToSpeech function.\n */\n\nimport {ai} from '@/ai/genkit';\nimport {z} from 'genkit';\nimport wav from 'wav';\nimport { googleAI } from '@genkit-ai/googleai';\n\nconst TextToSpeechInputSchema = z.object({\n  text: z.string().describe('The text to convert to speech.'),\n});\nexport type TextToSpeechInput = z.infer<typeof TextToSpeechInputSchema>;\n\nconst TextToSpeechOutputSchema = z.object({\n  audioDataUri: z\n    .string()\n    .describe(\n      \"The generated audio as a data URI that must include a MIME type and use Base64 encoding. Expected format: 'data:<mimetype>;base64,<encoded_data>'.\"\n    ),\n});\nexport type TextToSpeechOutput = z.infer<typeof TextToSpeechOutputSchema>;\n\nexport async function textToSpeech(input: TextToSpeechInput): Promise<TextToSpeechOutput> {\n  return textToSpeechFlow(input);\n}\n\nasync function toWav(\n  pcmData: Buffer,\n  channels = 1,\n  rate = 24000,\n  sampleWidth = 2\n): Promise<string> {\n  return new Promise((resolve, reject) => {\n    const writer = new wav.Writer({\n      channels,\n      sampleRate: rate,\n      bitDepth: sampleWidth * 8,\n    });\n\n    let bufs = [] as any[];\n    writer.on('error', reject);\n    writer.on('data', function (d) {\n      bufs.push(d);\n    });\n    writer.on('end', function () {\n      resolve(Buffer.concat(bufs).toString('base64'));\n    });\n\n    writer.write(pcmData);\n    writer.end();\n  });\n}\n\nconst textToSpeechFlow = ai.defineFlow(\n  {\n    name: 'textToSpeechFlow',\n    inputSchema: TextToSpeechInputSchema,\n    outputSchema: TextToSpeechOutputSchema,\n  },\n  async ({text}) => {\n    const { media } = await ai.generate({\n      model: googleAI.model('gemini-2.5-flash-preview-tts'),\n      config: {\n        responseModalities: ['AUDIO'],\n        speechConfig: {\n          voiceConfig: {\n            prebuiltVoiceConfig: { voiceName: 'Algenib' },\n          },\n        },\n      },\n      prompt: text,\n    });\n    if (!media) {\n      throw new Error('No media returned from TTS model');\n    }\n    const audioBuffer = Buffer.from(\n      media.url.substring(media.url.indexOf(',') + 1),\n      'base64'\n    );\n    const wavBase64 = await toWav(audioBuffer);\n    \n    return {\n      audioDataUri: 'data:audio/wav;base64,' + wavBase64,\n    };\n  }\n);\n"],"names":[],"mappings":";;;;;AAEA;;;;;;CAMC,GAED;AACA;AAAA;AACA;AACA;AAAA;;;;;;;;AAEA,MAAM,0BAA0B,uIAAA,CAAA,IAAC,CAAC,MAAM,CAAC;IACvC,MAAM,uIAAA,CAAA,IAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;AAC5B;AAGA,MAAM,2BAA2B,uIAAA,CAAA,IAAC,CAAC,MAAM,CAAC;IACxC,cAAc,uIAAA,CAAA,IAAC,CACZ,MAAM,GACN,QAAQ,CACP;AAEN;AAGO,eAAe,aAAa,KAAwB;IACzD,OAAO,iBAAiB;AAC1B;AAEA,eAAe,MACb,OAAe,EACf,WAAW,CAAC,EACZ,OAAO,KAAK,EACZ,cAAc,CAAC;IAEf,OAAO,IAAI,QAAQ,CAAC,SAAS;QAC3B,MAAM,SAAS,IAAI,4HAAA,CAAA,UAAG,CAAC,MAAM,CAAC;YAC5B;YACA,YAAY;YACZ,UAAU,cAAc;QAC1B;QAEA,IAAI,OAAO,EAAE;QACb,OAAO,EAAE,CAAC,SAAS;QACnB,OAAO,EAAE,CAAC,QAAQ,SAAU,CAAC;YAC3B,KAAK,IAAI,CAAC;QACZ;QACA,OAAO,EAAE,CAAC,OAAO;YACf,QAAQ,OAAO,MAAM,CAAC,MAAM,QAAQ,CAAC;QACvC;QAEA,OAAO,KAAK,CAAC;QACb,OAAO,GAAG;IACZ;AACF;AAEA,MAAM,mBAAmB,mHAAA,CAAA,KAAE,CAAC,UAAU,CACpC;IACE,MAAM;IACN,aAAa;IACb,cAAc;AAChB,GACA,OAAO,EAAC,IAAI,EAAC;IACX,MAAM,EAAE,KAAK,EAAE,GAAG,MAAM,mHAAA,CAAA,KAAE,CAAC,QAAQ,CAAC;QAClC,OAAO,2KAAA,CAAA,WAAQ,CAAC,KAAK,CAAC;QACtB,QAAQ;YACN,oBAAoB;gBAAC;aAAQ;YAC7B,cAAc;gBACZ,aAAa;oBACX,qBAAqB;wBAAE,WAAW;oBAAU;gBAC9C;YACF;QACF;QACA,QAAQ;IACV;IACA,IAAI,CAAC,OAAO;QACV,MAAM,IAAI,MAAM;IAClB;IACA,MAAM,cAAc,OAAO,IAAI,CAC7B,MAAM,GAAG,CAAC,SAAS,CAAC,MAAM,GAAG,CAAC,OAAO,CAAC,OAAO,IAC7C;IAEF,MAAM,YAAY,MAAM,MAAM;IAE9B,OAAO;QACL,cAAc,2BAA2B;IAC3C;AACF;;;IA9DoB;;AAAA,+OAAA","debugId":null}},
    {"offset": {"line": 439, "column": 0}, "map": {"version":3,"sources":["file:///home/user/studio/src/ai/flows/speech-to-text.ts"],"sourcesContent":["\n'use server';\n/**\n * @fileOverview A speech-to-text AI flow using Google Cloud Speech-to-Text v2.\n *\n * - speechToText - A function that converts audio to text.\n * - SpeechToTextInput - The input type for the speechToText function.\n * - SpeechToTextOutput - The return type for the speechToText function.\n */\n\nimport { ai } from '@/ai/genkit';\nimport { z } from 'genkit';\nimport { SpeechClient } from '@google-cloud/speech';\nimport { config } from 'dotenv';\n\nconfig();\n\nconst SpeechToTextInputSchema = z.object({\n  audioDataUri: z\n    .string()\n    .describe(\n      \"The audio to transcribe, as a data URI that must include a MIME type and use Base64 encoding. Expected format: 'data:<mimetype>;base64,<encoded_data>'\"\n    ),\n  languageCode: z.string().optional().describe('The language of the audio. Defaults to en-US.'),\n});\nexport type SpeechToTextInput = z.infer<typeof SpeechToTextInputSchema>;\n\nconst SpeechToTextOutputSchema = z.object({\n  transcript: z.string().describe('The transcribed text.'),\n});\nexport type SpeechToTextOutput = z.infer<typeof SpeechToTextOutputSchema>;\n\nexport async function speechToText(input: SpeechToTextInput): Promise<SpeechToTextOutput> {\n  return speechToTextFlow(input);\n}\n\nconst speechToTextFlow = ai.defineFlow(\n  {\n    name: 'speechToTextFlow',\n    inputSchema: SpeechToTextInputSchema,\n    outputSchema: SpeechToTextOutputSchema,\n  },\n  async ({ audioDataUri, languageCode = 'en-US' }) => {\n    // This flow now uses the v2 Speech-to-Text client.\n    const speechClient = new SpeechClient();\n\n    const audioBytes = audioDataUri.split(',')[1];\n    \n    // The project ID is required for v2 recognizers.\n    // It's retrieved from environment variables, which App Hosting provides.\n    const projectId = process.env.GCLOUD_PROJECT;\n    if (!projectId) {\n        // This feature requires Google Cloud credentials and a project ID,\n        // which are provided automatically when deployed to Firebase App Hosting.\n        // It will not work in a local development environment without manual setup.\n        console.warn(\"GCLOUD_PROJECT environment variable not set. Speech-to-text will not work locally without manual configuration.\");\n        return { transcript: \"Speech-to-text is not available in the local environment.\" };\n    }\n\n    const request = {\n      recognizer: `projects/${projectId}/locations/global/recognizers/_`,\n      config: {\n        autoDecodingConfig: {},\n        model: 'chirp',\n        languageCodes: [languageCode],\n      },\n      content: audioBytes,\n    };\n\n    try {\n        const [response] = await speechClient.recognize(request);\n        const transcription = response.results\n            ?.map(result => result.alternatives?.[0].transcript)\n            .join('\\n');\n\n        return {\n            transcript: transcription || '',\n        };\n    } catch (error) {\n        console.error('Speech-to-text API v2 error:', error);\n        throw new Error('Failed to transcribe audio.');\n    }\n  }\n);\n"],"names":[],"mappings":";;;;;AAEA;;;;;;CAMC,GAED;AACA;AAAA;AACA;AACA;;;;;;;;AAEA,CAAA,GAAA,qIAAA,CAAA,SAAM,AAAD;AAEL,MAAM,0BAA0B,uIAAA,CAAA,IAAC,CAAC,MAAM,CAAC;IACvC,cAAc,uIAAA,CAAA,IAAC,CACZ,MAAM,GACN,QAAQ,CACP;IAEJ,cAAc,uIAAA,CAAA,IAAC,CAAC,MAAM,GAAG,QAAQ,GAAG,QAAQ,CAAC;AAC/C;AAGA,MAAM,2BAA2B,uIAAA,CAAA,IAAC,CAAC,MAAM,CAAC;IACxC,YAAY,uIAAA,CAAA,IAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;AAClC;AAGO,eAAe,aAAa,KAAwB;IACzD,OAAO,iBAAiB;AAC1B;AAEA,MAAM,mBAAmB,mHAAA,CAAA,KAAE,CAAC,UAAU,CACpC;IACE,MAAM;IACN,aAAa;IACb,cAAc;AAChB,GACA,OAAO,EAAE,YAAY,EAAE,eAAe,OAAO,EAAE;IAC7C,mDAAmD;IACnD,MAAM,eAAe,IAAI,oKAAA,CAAA,eAAY;IAErC,MAAM,aAAa,aAAa,KAAK,CAAC,IAAI,CAAC,EAAE;IAE7C,iDAAiD;IACjD,yEAAyE;IACzE,MAAM,YAAY,QAAQ,GAAG,CAAC,cAAc;IAC5C,IAAI,CAAC,WAAW;QACZ,mEAAmE;QACnE,0EAA0E;QAC1E,4EAA4E;QAC5E,QAAQ,IAAI,CAAC;QACb,OAAO;YAAE,YAAY;QAA4D;IACrF;IAEA,MAAM,UAAU;QACd,YAAY,CAAC,SAAS,EAAE,UAAU,+BAA+B,CAAC;QAClE,QAAQ;YACN,oBAAoB,CAAC;YACrB,OAAO;YACP,eAAe;gBAAC;aAAa;QAC/B;QACA,SAAS;IACX;IAEA,IAAI;QACA,MAAM,CAAC,SAAS,GAAG,MAAM,aAAa,SAAS,CAAC;QAChD,MAAM,gBAAgB,SAAS,OAAO,EAChC,IAAI,CAAA,SAAU,OAAO,YAAY,EAAE,CAAC,EAAE,CAAC,YACxC,KAAK;QAEV,OAAO;YACH,YAAY,iBAAiB;QACjC;IACJ,EAAE,OAAO,OAAO;QACZ,QAAQ,KAAK,CAAC,gCAAgC;QAC9C,MAAM,IAAI,MAAM;IACpB;AACF;;;IAlDoB;;AAAA,+OAAA","debugId":null}},
    {"offset": {"line": 526, "column": 0}, "map": {"version":3,"sources":["file:///home/user/studio/.next-internal/server/app/page/actions.js%20%28server%20actions%20loader%29"],"sourcesContent":["export {teachAnything as '40f4e56a2b2c9e62cbc0c3320c3c6d55217611e928'} from 'ACTIONS_MODULE0'\nexport {textToSpeech as '40c4c028a33451231b59cf1a0b26b6081ec53fd430'} from 'ACTIONS_MODULE1'\nexport {speechToText as '40899377b4dc2f0b03cb0d94e7875ab718376acf0b'} from 'ACTIONS_MODULE2'\n"],"names":[],"mappings":";AAAA;AACA;AACA","debugId":null}},
    {"offset": {"line": 590, "column": 0}, "map": {"version":3,"sources":["file:///home/user/studio/src/app/dashboard-client.tsx/proxy.mjs"],"sourcesContent":["import { registerClientReference } from \"react-server-dom-turbopack/server.edge\";\nexport const DashboardClient = registerClientReference(\n    function() { throw new Error(\"Attempted to call DashboardClient() from the server but DashboardClient is on the client. It's not possible to invoke a client function from the server, it can only be rendered as a Component or passed to props of a Client Component.\"); },\n    \"[project]/src/app/dashboard-client.tsx <module evaluation>\",\n    \"DashboardClient\",\n);\n"],"names":[],"mappings":";;;AAAA;;AACO,MAAM,kBAAkB,CAAA,GAAA,qPAAA,CAAA,0BAAuB,AAAD,EACjD;IAAa,MAAM,IAAI,MAAM;AAA8O,GAC3Q,8DACA","debugId":null}},
    {"offset": {"line": 604, "column": 0}, "map": {"version":3,"sources":["file:///home/user/studio/src/app/dashboard-client.tsx/proxy.mjs"],"sourcesContent":["import { registerClientReference } from \"react-server-dom-turbopack/server.edge\";\nexport const DashboardClient = registerClientReference(\n    function() { throw new Error(\"Attempted to call DashboardClient() from the server but DashboardClient is on the client. It's not possible to invoke a client function from the server, it can only be rendered as a Component or passed to props of a Client Component.\"); },\n    \"[project]/src/app/dashboard-client.tsx\",\n    \"DashboardClient\",\n);\n"],"names":[],"mappings":";;;AAAA;;AACO,MAAM,kBAAkB,CAAA,GAAA,qPAAA,CAAA,0BAAuB,AAAD,EACjD;IAAa,MAAM,IAAI,MAAM;AAA8O,GAC3Q,0CACA","debugId":null}},
    {"offset": {"line": 618, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"","debugId":null}},
    {"offset": {"line": 628, "column": 0}, "map": {"version":3,"sources":["file:///home/user/studio/src/app/page.tsx"],"sourcesContent":["\nimport { DashboardClient } from \"@/app/dashboard-client\";\n\nexport default function Home() {\n  return (\n    <div className=\"flex flex-col h-[calc(100vh-8rem)]\">\n      <DashboardClient />\n    </div>\n  );\n}\n"],"names":[],"mappings":";;;;AACA;;;AAEe,SAAS;IACtB,qBACE,8OAAC;QAAI,WAAU;kBACb,cAAA,8OAAC,kIAAA,CAAA,kBAAe;;;;;;;;;;AAGtB","debugId":null}}]
}